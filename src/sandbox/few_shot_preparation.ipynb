{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuansui/miniconda3/envs/rog/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-23 15:51:21,655] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "# prepare the few_shot samples\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "import wandb\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import copy\n",
    "from src.qa_prediction.evaluate_results import eval_result\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from openai import OpenAI\n",
    "from datasets import load_dataset\n",
    "from src import utils\n",
    "from src.utils import prompt_list_cwq, prompt_list_webqsp\n",
    "\n",
    "dataset_name = \"rmanluo/RoG-webqsp\"\n",
    "\n",
    "dataset = load_dataset(dataset_name, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2826/2826 [00:52<00:00, 54.18it/s]\n"
     ]
    }
   ],
   "source": [
    "id_list = [\n",
    "   \"WebQTrn-471\",\n",
    "   \"WebQTrn-485\",\n",
    "   \"WebQTrn-928\",\n",
    "   \"WebQTrn-999\",\n",
    "   \"WebQTrn-2016\"\n",
    "]\n",
    "\n",
    "shot_list = []\n",
    "for data in tqdm(dataset):\n",
    "   if data[\"id\"] in id_list:\n",
    "      shot_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tuples_to_string(tuples):\n",
    "   elements = []\n",
    "   for tup in tuples:\n",
    "      for element in tup:\n",
    "         if element not in elements:\n",
    "               elements.append(element)\n",
    "   return \"->\".join(elements) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(texts, model=\"text-embedding-3-small\"):\n",
    "    client = OpenAI(api_key=\"xx\")\n",
    "    response = client.embeddings.create(\n",
    "        model=model, input=texts\n",
    "    )\n",
    "    return [item.embedding for item in response.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_options_for_each_step(q_entity, query, graph, next_entity=\"None\") -> list:\n",
    "    \"\"\"\n",
    "    prepare options for each step of the reasoning path\n",
    "    \"\"\"\n",
    "    if next_entity == \"None\":\n",
    "        raw_options = utils.get_entity_edges([q_entity], graph)\n",
    "    else:\n",
    "        raw_options = utils.get_entity_edges([next_entity], graph) # get edges of the entities \n",
    "    \n",
    "    def vector_rag_engine(query, options, top_k=10):\n",
    "        print(\"query: \", query)\n",
    "        print(\"options: \", options)\n",
    "        texts = [query] + options\n",
    "        embeddings = get_embedding(texts)\n",
    "        query_embedding = np.array(embeddings[0])\n",
    "        option_embeddings = np.array(embeddings[1:])\n",
    "        similarities = cosine_similarity([query_embedding], option_embeddings)\n",
    "        top_k_indices = np.argsort(similarities[0])[-top_k:][::-1]\n",
    "        top_k_options = [options[i] for i in top_k_indices]\n",
    "        # corresponding_neighbors = [neighbors[i] for i in top_k_indices]\n",
    "        \n",
    "        return top_k_options\n",
    "        # return [f\"{i+1}: {option} -> {neighbor}\" for i, (option, neighbor) in enumerate(zip(top_k_options, corresponding_neighbors))]\n",
    "    \n",
    "    retrieved_options = vector_rag_engine(query, raw_options) # de-duplicate the same options\n",
    "    processed_options = []\n",
    "    for i, option in enumerate(retrieved_options):\n",
    "        processed_options.append(f\"{i+1}: {option}\")\n",
    "\n",
    "    return processed_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  what art movements was henri matisse involved in\n",
      "options:  ([], [])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"tuple\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m negative_path_2_hop_str_list \u001b[38;5;241m=\u001b[39m [convert_tuples_to_string(path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m negative_path_2_hop]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# raw_options, neighbors = utils.get_entity_edges(data[\"q_entity\"], graph)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# raw_options = [f\"{i+1}: {option}\" for i, option in enumerate(raw_options)]\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m raw_options \u001b[38;5;241m=\u001b[39m prepare_options_for_each_step(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_entity\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m], graph)\n\u001b[1;32m     15\u001b[0m index_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, option \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(raw_options):\n",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m, in \u001b[0;36mprepare_options_for_each_step\u001b[0;34m(q_entity, query, graph, next_entity)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m top_k_options\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# return [f\"{i+1}: {option} -> {neighbor}\" for i, (option, neighbor) in enumerate(zip(top_k_options, corresponding_neighbors))]\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m retrieved_options \u001b[38;5;241m=\u001b[39m \u001b[43mvector_rag_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_options\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# de-duplicate the same options\u001b[39;00m\n\u001b[1;32m     26\u001b[0m processed_options \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, option \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(retrieved_options):\n",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m, in \u001b[0;36mprepare_options_for_each_step.<locals>.vector_rag_engine\u001b[0;34m(query, options, top_k)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery: \u001b[39m\u001b[38;5;124m\"\u001b[39m, query)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions: \u001b[39m\u001b[38;5;124m\"\u001b[39m, options)\n\u001b[0;32m---> 13\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\n\u001b[1;32m     14\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m get_embedding(texts)\n\u001b[1;32m     15\u001b[0m query_embedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(embeddings[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"tuple\") to list"
     ]
    }
   ],
   "source": [
    "async with aiohttp.ClientSession() as session:\n",
    "   for data in shot_list:\n",
    "      graph = utils.build_graph(data[\"graph\"])\n",
    "      shortest_paths = utils.get_truth_paths(data[\"q_entity\"], data[\"a_entity\"], graph)\n",
    "      negative_path_1_hop = utils.get_negative_paths(data[\"q_entity\"], data[\"a_entity\"], graph, n_neg=2, hop=2)\n",
    "      negative_path_2_hop = utils.get_negative_paths(data[\"q_entity\"], data[\"a_entity\"], graph, n_neg=2, hop=3)\n",
    "      shortest_paths_str_list = [convert_tuples_to_string(path) for path in shortest_paths]\n",
    "      negative_path_1_hop_str_list = [convert_tuples_to_string(path) for path in negative_path_1_hop]\n",
    "      negative_path_2_hop_str_list = [convert_tuples_to_string(path) for path in negative_path_2_hop]\n",
    "      # raw_options, neighbors = utils.get_entity_edges(data[\"q_entity\"], graph)\n",
    "      # raw_options = [f\"{i+1}: {option}\" for i, option in enumerate(raw_options)]\n",
    "      \n",
    "      raw_options = prepare_options_for_each_step(data[\"q_entity\"], data[\"question\"], graph)\n",
    "      \n",
    "      index_list = []\n",
    "      for i, option in enumerate(raw_options):\n",
    "         for path in shortest_paths_str_list:\n",
    "            if path.__contains__(option.split(\": \")[1]):\n",
    "               index_list.append(i+1)\n",
    "               \n",
    "      raw_options = \"\\n\".join(raw_options)\n",
    "      sample_list.append({\n",
    "         \"id\": data[\"id\"],\n",
    "         \"question\": data[\"question\"],\n",
    "         \"q_entity\": data[\"q_entity\"],\n",
    "         \"a_entity\": data[\"a_entity\"],\n",
    "         \"raw_options\": raw_options,\n",
    "         \"index_list\": index_list,\n",
    "         \"shortest_paths\": shortest_paths_str_list,\n",
    "         \"negative_path_1_hop\": negative_path_1_hop_str_list,\n",
    "         \"negative_path_2_hop\": negative_path_2_hop_str_list\n",
    "      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in shot_list:\n",
    "   graph = utils.build_graph(data[\"graph\"])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'prompts/few_shot_samples_webqsp.txt', 'w') as file:\n",
    "   file.write(json.dumps(sample_list, indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Selena Gomez->people.person.places_lived->m.04hmnxs->people.place_lived.location->New York City',\n",
       " 'Selena Gomez->people.person.nationality->United States of America->location.location.containedby->New York City']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_paths_str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Selena Gomez', 'music.artist.label', 'Avex Trax'),\n",
       "  ('Avex Trax',\n",
       "   'music.record_label.releases',\n",
       "   'Super Eurobeat, Volume 110: Millennium Anniversary Non-Stop Megamix')],\n",
       " [('Selena Gomez', 'music.artist.track', 'Do It'),\n",
       "  ('Do It', 'music.artist.track', 'Selena Gomez')]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_path_2_hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Selena Gomez', 'people.person.places_lived', 'm.04hmnxs'),\n",
       "  ('m.04hmnxs', 'people.place_lived.location', 'New York City')],\n",
       " [('Selena Gomez', 'people.person.nationality', 'United States of America'),\n",
       "  ('United States of America',\n",
       "   'location.location.containedby',\n",
       "   'New York City')]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Selena Gomez']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"q_entity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"adasda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"1: adasda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Given a question and the starting entity from a knowledge graph, you are asked to answer whether it's sufficient for you to answer the question with the following reasoning path. \\nQuestion: what did james k polk do before he was president \\nReasoning path: James K. Polk->\\nbase.kwebbase.kwtopic.has_sentences->In 1825 Polk was elected to the U.S. House of Representatives, where he continued his support of Jackson, even though the House had passed him over as President in favor of John Quincy Adams .\\nbase.kwebbase.kwsentence.kwtopic->In 1835, Jackson rewarded Polk by making him Speaker of the House.\\nbase.kwebbase.kwsentence.kwtopic->In 1839, in an effort to win back Tennessee for the Democrats, Polk resigned as Speaker and ran for State Governor.\\nbase.kwebbase.kwsentence.kwtopic->As he set about replacing federalists with loyal Democrats, Polk was deluged with job applicants, and some of his choices nettled the administration.\\nbase.kwebbase.kwsentence.kwtopic->Four years later, when Jackson became President, Polk worked tirelessly on Jackson's program.\\nIf it is sufficient to answer the question, respond with 'Yes'; otherwise, respond with 'No'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Given a question and the starting entity from a knowledge graph, you are asked to answer whether it's sufficient for you to answer the question with the following reasoning path. \\nQuestion: what did james k polk do before he was president \\nReasoning path: James K. Polk->\\nbase.kwebbase.kwtopic.has_sentences->In 1825 Polk was elected to the U.S. House of Representatives, where he continued his support of Jackson, even though the House had passed him over as President in favor of John Quincy Adams .\\nbase.kwebbase.kwsentence.kwtopic->In 1835, Jackson rewarded Polk by making him Speaker of the House.\\nbase.kwebbase.kwsentence.kwtopic->In 1839, in an effort to win back Tennessee for the Democrats, Polk resigned as Speaker and ran for State Governor.\\nbase.kwebbase.kwsentence.kwtopic->As he set about replacing federalists with loyal Democrats, Polk was deluged with job applicants, and some of his choices nettled the administration.\\nbase.kwebbase.kwsentence.kwtopic->Four years later, when Jackson became President, Polk worked tirelessly on Jackson's program.\\nIf it is sufficient to answer the question, respond with 'Yes'; otherwise, respond with 'No'\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= \"Answer: [Yes, Yes, Yes, Yes, Yes]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/rog/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[12], line 1\u001b[0m\n    termination_checks = ast.literal_eval(x)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/rog/lib/python3.9/ast.py:62\u001b[0m in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string, mode='eval')\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniconda3/envs/rog/lib/python3.9/ast.py:50\u001b[0;36m in \u001b[0;35mparse\u001b[0;36m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Answer: [Yes, Yes, Yes, Yes, Yes]\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "termination_checks = ast.literal_eval(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Jamaican English\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jamaican English']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jamaican English']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.replace(\"Answer: \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# The string from which you want to extract the list of numbers\n",
    "input_string = \"Selected reasoning paths: [31, 32, 33, 34, 35]\"\n",
    "\n",
    "# Use regular expression to find all occurrences of one or more digits\n",
    "matches = re.findall(r'\\d+', input_string)\n",
    "\n",
    "# Convert the found strings to integers\n",
    "extracted_numbers = [int(match) for match in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31, 32, 33, 34, 35]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
